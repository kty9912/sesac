{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ea3e902",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce5d828e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_IN_PATH = './data_in/'\n",
    "TRAIN_CLEAN_DATA = 'train_clean.csv'\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "TEST_SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13657b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(DATA_IN_PATH + TRAIN_CLEAN_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9cb258c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = list(train_data['review'])\n",
    "sentiments = list(train_data['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8932dd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for review in reviews:\n",
    "    sentences.append(review.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d45c4008",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 300     #  단어에 대해 임베딩된 벡터의 차원   \n",
    "min_word_count = 40  # 적은 빈도수 배제용 \n",
    "num_workers = 4      #  학습을 위한 프로세스 개수 지정\n",
    "context = 10          # 컨텍스트 윈도우 크기 지정\n",
    "downsampling = 1e-3 # 빠른 학습을 위해 정답 단어 레이블에 대한 다운샘플링 \n",
    "                    # 비율 지정(보통 0.001이 좋은 성능을 낸다고 함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9941ef84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "# level=logging.INFO : word2vec의 학습 과정에서 로그 메시지를 양식에 맞게 -\n",
    "# - info 수준으로 보여줌\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\\\n",
    "   level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcf8c684",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-07 16:54:14,512 : INFO : collecting all words and their counts\n",
      "2022-11-07 16:54:14,519 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-11-07 16:54:15,270 : INFO : PROGRESS: at sentence #10000, processed 1205223 words, keeping 51374 word types\n",
      "2022-11-07 16:54:15,769 : INFO : PROGRESS: at sentence #20000, processed 2396605 words, keeping 67660 word types\n",
      "2022-11-07 16:54:16,048 : INFO : collected 74065 word types from a corpus of 2988089 raw words and 25000 sentences\n",
      "2022-11-07 16:54:16,049 : INFO : Creating a fresh vocabulary\n",
      "2022-11-07 16:54:16,215 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=40 retains 8160 unique words (11.017349625329103%% of original 74065, drops 65905)', 'datetime': '2022-11-07T16:54:16.215497', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'prepare_vocab'}\n",
      "2022-11-07 16:54:16,216 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=40 leaves 2627273 word corpus (87.92485765986221%% of original 2988089, drops 360816)', 'datetime': '2022-11-07T16:54:16.216498', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'prepare_vocab'}\n",
      "2022-11-07 16:54:16,368 : INFO : deleting the raw counts dictionary of 74065 items\n",
      "2022-11-07 16:54:16,374 : INFO : sample=0.001 downsamples 30 most-common words\n",
      "2022-11-07 16:54:16,377 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 2494384.49928802 word corpus (94.9%% of prior 2627273)', 'datetime': '2022-11-07T16:54:16.377986', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'prepare_vocab'}\n",
      "2022-11-07 16:54:16,560 : INFO : estimated required memory for 8160 words and 300 dimensions: 23664000 bytes\n",
      "2022-11-07 16:54:16,561 : INFO : resetting layer weights\n",
      "2022-11-07 16:54:16,603 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-11-07T16:54:16.603490', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'build_vocab'}\n",
      "2022-11-07 16:54:16,604 : INFO : Word2Vec lifecycle event {'msg': 'training model with 4 workers on 8160 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2022-11-07T16:54:16.604481', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'train'}\n",
      "2022-11-07 16:54:17,694 : INFO : EPOCH 1 - PROGRESS: at 8.24% examples, 193479 words/s, in_qsize 8, out_qsize 0\n",
      "2022-11-07 16:54:18,733 : INFO : EPOCH 1 - PROGRESS: at 14.38% examples, 172400 words/s, in_qsize 7, out_qsize 0\n",
      "2022-11-07 16:54:19,736 : INFO : EPOCH 1 - PROGRESS: at 30.79% examples, 249898 words/s, in_qsize 8, out_qsize 0\n",
      "2022-11-07 16:54:20,746 : INFO : EPOCH 1 - PROGRESS: at 42.16% examples, 257081 words/s, in_qsize 7, out_qsize 0\n",
      "2022-11-07 16:54:21,749 : INFO : EPOCH 1 - PROGRESS: at 57.92% examples, 284318 words/s, in_qsize 7, out_qsize 0\n",
      "2022-11-07 16:54:22,763 : INFO : EPOCH 1 - PROGRESS: at 73.01% examples, 298249 words/s, in_qsize 7, out_qsize 0\n",
      "2022-11-07 16:54:23,774 : INFO : EPOCH 1 - PROGRESS: at 94.46% examples, 330160 words/s, in_qsize 7, out_qsize 0\n",
      "2022-11-07 16:54:24,020 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-11-07 16:54:24,029 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-11-07 16:54:24,031 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-11-07 16:54:24,070 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-11-07 16:54:24,071 : INFO : EPOCH - 1 : training on 2988089 raw words (2494556 effective words) took 7.4s, 335153 effective words/s\n",
      "2022-11-07 16:54:25,096 : INFO : EPOCH 2 - PROGRESS: at 23.56% examples, 584313 words/s, in_qsize 7, out_qsize 0\n",
      "2022-11-07 16:54:26,106 : INFO : EPOCH 2 - PROGRESS: at 36.66% examples, 456610 words/s, in_qsize 8, out_qsize 0\n",
      "2022-11-07 16:54:27,156 : INFO : EPOCH 2 - PROGRESS: at 44.45% examples, 362799 words/s, in_qsize 7, out_qsize 0\n",
      "2022-11-07 16:54:28,168 : INFO : EPOCH 2 - PROGRESS: at 52.35% examples, 321750 words/s, in_qsize 8, out_qsize 1\n",
      "2022-11-07 16:54:29,179 : INFO : EPOCH 2 - PROGRESS: at 64.37% examples, 316453 words/s, in_qsize 7, out_qsize 0\n",
      "2022-11-07 16:54:30,202 : INFO : EPOCH 2 - PROGRESS: at 74.29% examples, 304202 words/s, in_qsize 7, out_qsize 0\n",
      "2022-11-07 16:54:31,226 : INFO : EPOCH 2 - PROGRESS: at 86.88% examples, 304644 words/s, in_qsize 8, out_qsize 0\n",
      "2022-11-07 16:54:32,301 : INFO : EPOCH 2 - PROGRESS: at 98.50% examples, 298943 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-07 16:54:32,321 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-11-07 16:54:32,329 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-11-07 16:54:32,380 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-11-07 16:54:32,468 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-11-07 16:54:32,473 : INFO : EPOCH - 2 : training on 2988089 raw words (2494315 effective words) took 8.4s, 297138 effective words/s\n",
      "2022-11-07 16:54:33,676 : INFO : EPOCH 3 - PROGRESS: at 11.23% examples, 263790 words/s, in_qsize 7, out_qsize 0\n",
      "2022-11-07 16:54:34,716 : INFO : EPOCH 3 - PROGRESS: at 17.26% examples, 207817 words/s, in_qsize 8, out_qsize 0\n",
      "2022-11-07 16:54:35,717 : INFO : EPOCH 3 - PROGRESS: at 29.82% examples, 242342 words/s, in_qsize 7, out_qsize 0\n",
      "2022-11-07 16:54:36,723 : INFO : EPOCH 3 - PROGRESS: at 39.12% examples, 239389 words/s, in_qsize 7, out_qsize 0\n",
      "2022-11-07 16:54:37,840 : INFO : EPOCH 3 - PROGRESS: at 50.00% examples, 240578 words/s, in_qsize 7, out_qsize 0\n",
      "2022-11-07 16:54:38,877 : INFO : EPOCH 3 - PROGRESS: at 58.56% examples, 235078 words/s, in_qsize 6, out_qsize 1\n",
      "2022-11-07 16:54:39,884 : INFO : EPOCH 3 - PROGRESS: at 72.32% examples, 249337 words/s, in_qsize 7, out_qsize 0\n",
      "2022-11-07 16:54:40,921 : INFO : EPOCH 3 - PROGRESS: at 84.33% examples, 254115 words/s, in_qsize 8, out_qsize 1\n",
      "2022-11-07 16:54:41,928 : INFO : EPOCH 3 - PROGRESS: at 95.15% examples, 255058 words/s, in_qsize 8, out_qsize 0\n",
      "2022-11-07 16:54:42,474 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-11-07 16:54:42,477 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-11-07 16:54:42,565 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-11-07 16:54:42,636 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-11-07 16:54:42,639 : INFO : EPOCH - 3 : training on 2988089 raw words (2494553 effective words) took 10.0s, 248760 effective words/s\n",
      "2022-11-07 16:54:43,756 : INFO : EPOCH 4 - PROGRESS: at 11.52% examples, 286698 words/s, in_qsize 8, out_qsize 0\n",
      "2022-11-07 16:54:44,773 : INFO : EPOCH 4 - PROGRESS: at 21.79% examples, 273244 words/s, in_qsize 7, out_qsize 0\n",
      "2022-11-07 16:54:45,784 : INFO : EPOCH 4 - PROGRESS: at 35.08% examples, 291253 words/s, in_qsize 8, out_qsize 0\n",
      "2022-11-07 16:54:46,789 : INFO : EPOCH 4 - PROGRESS: at 46.47% examples, 288450 words/s, in_qsize 8, out_qsize 1\n",
      "2022-11-07 16:54:47,795 : INFO : EPOCH 4 - PROGRESS: at 55.57% examples, 276987 words/s, in_qsize 7, out_qsize 0\n",
      "2022-11-07 16:54:48,832 : INFO : EPOCH 4 - PROGRESS: at 66.06% examples, 272128 words/s, in_qsize 7, out_qsize 0\n",
      "2022-11-07 16:54:49,894 : INFO : EPOCH 4 - PROGRESS: at 72.96% examples, 256020 words/s, in_qsize 8, out_qsize 1\n",
      "2022-11-07 16:54:50,903 : INFO : EPOCH 4 - PROGRESS: at 81.75% examples, 250775 words/s, in_qsize 8, out_qsize 0\n",
      "2022-11-07 16:54:51,960 : INFO : EPOCH 4 - PROGRESS: at 90.37% examples, 245399 words/s, in_qsize 7, out_qsize 0\n",
      "2022-11-07 16:54:52,709 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-11-07 16:54:52,735 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-11-07 16:54:52,836 : INFO : worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-07 16:54:52,848 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-11-07 16:54:52,849 : INFO : EPOCH - 4 : training on 2988089 raw words (2494538 effective words) took 10.1s, 246927 effective words/s\n",
      "2022-11-07 16:54:53,925 : INFO : EPOCH 5 - PROGRESS: at 8.24% examples, 206050 words/s, in_qsize 7, out_qsize 0\n",
      "2022-11-07 16:54:54,970 : INFO : EPOCH 5 - PROGRESS: at 17.88% examples, 221864 words/s, in_qsize 7, out_qsize 0\n",
      "2022-11-07 16:54:56,026 : INFO : EPOCH 5 - PROGRESS: at 27.24% examples, 221164 words/s, in_qsize 8, out_qsize 0\n",
      "2022-11-07 16:54:57,041 : INFO : EPOCH 5 - PROGRESS: at 34.47% examples, 210834 words/s, in_qsize 7, out_qsize 0\n",
      "2022-11-07 16:54:58,072 : INFO : EPOCH 5 - PROGRESS: at 45.43% examples, 221645 words/s, in_qsize 7, out_qsize 0\n",
      "2022-11-07 16:54:59,083 : INFO : EPOCH 5 - PROGRESS: at 51.68% examples, 210913 words/s, in_qsize 8, out_qsize 0\n",
      "2022-11-07 16:55:00,101 : INFO : EPOCH 5 - PROGRESS: at 58.55% examples, 205194 words/s, in_qsize 8, out_qsize 0\n",
      "2022-11-07 16:55:01,127 : INFO : EPOCH 5 - PROGRESS: at 65.43% examples, 199849 words/s, in_qsize 6, out_qsize 1\n",
      "2022-11-07 16:55:02,421 : INFO : EPOCH 5 - PROGRESS: at 71.33% examples, 188339 words/s, in_qsize 7, out_qsize 0\n",
      "2022-11-07 16:55:03,431 : INFO : EPOCH 5 - PROGRESS: at 82.06% examples, 195451 words/s, in_qsize 8, out_qsize 0\n",
      "2022-11-07 16:55:04,498 : INFO : EPOCH 5 - PROGRESS: at 91.69% examples, 198140 words/s, in_qsize 8, out_qsize 0\n",
      "2022-11-07 16:55:05,554 : INFO : EPOCH 5 - PROGRESS: at 99.18% examples, 195973 words/s, in_qsize 3, out_qsize 1\n",
      "2022-11-07 16:55:05,556 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-11-07 16:55:05,566 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-11-07 16:55:05,568 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-11-07 16:55:05,623 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-11-07 16:55:05,625 : INFO : EPOCH - 5 : training on 2988089 raw words (2494507 effective words) took 12.7s, 196397 effective words/s\n",
      "2022-11-07 16:55:05,628 : INFO : Word2Vec lifecycle event {'msg': 'training on 14940445 raw words (12472469 effective words) took 49.0s, 254423 effective words/s', 'datetime': '2022-11-07T16:55:05.628870', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'train'}\n",
      "2022-11-07 16:55:05,639 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=8160, vector_size=300, alpha=0.025)', 'datetime': '2022-11-07T16:55:05.639845', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import word2vec\n",
    "\n",
    "model = word2vec.Word2Vec(sentences, workers=num_workers, \\\n",
    "           vector_size=num_features, min_count = min_word_count, \\\n",
    "            window = context, sample = downsampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "378fc56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "words : 단어의 모음인 하나의 리뷰\n",
    "model : word2vec모델\n",
    "num_features : word2vec로 임베딩할 때 정했던 벡터의 차원 수\n",
    "'''\n",
    "def get_features(words, model, num_features):\n",
    "    # 출력 벡터 초기화\n",
    "    feature_vector = np.zeros((num_features),dtype=np.float32)\n",
    "    num_words = 0\n",
    "    # 어휘 사전 준비\n",
    "    index_to_key_set = set(model.wv.index_to_key)\n",
    "    \n",
    "    for w in words:\n",
    "        if w in index_to_key_set:\n",
    "            num_words += 1\n",
    "            # 사전에 해당하는 단어에 대해 단어 벡터를 더함\n",
    "            feature_vector = np.add(feature_vector, model.wv[w])\n",
    "            \n",
    "    feature_vector = np.divide(feature_vector, num_words)\n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f540c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(reviews, model, num_features):\n",
    "    dataset = list()\n",
    "\n",
    "    for s in reviews:\n",
    "        dataset.append(get_features(s, model, num_features))\n",
    "\n",
    "    reviewFeatureVecs = np.stack(dataset)\n",
    "    \n",
    "    return reviewFeatureVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b49200",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_vecs = get_dataset(sentences[:1], model, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb08360",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "X = test_data_vecs\n",
    "y = np.array(sentiments)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \\\n",
    "                            test_size=TEST_SPLIT, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e388c8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lgs = LogisticRegression(class_weight='balanced')\n",
    "lgs.fit(X_train, y_train)\n",
    "predicted = lgs.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7942c849",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(\"Accuracy: %f\" % lgs.score(X_test, y_test))  #checking the accuracy\n",
    "print(\"Precision: %f\" % metrics.precision_score(y_test, predicted))\n",
    "print(\"Recall: %f\" % metrics.recall_score(y_test, predicted))\n",
    "print(\"F1-Score: %f\" % metrics.f1_score(y_test, predicted))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.11 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "e99cd6124d1454c43974c193ef05ef59cc7820eb47b987c9c9e53e57b79f92b9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
