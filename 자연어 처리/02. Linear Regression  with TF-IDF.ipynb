{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_IN_PATH = './data_in/'\n",
    "DATA_OUT_PATH = './data_out/'\n",
    "TRAIN_CLEAN_DATA = 'train_clean.npy' # csv\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "TEST_SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(DATA_IN_PATH + TRAIN_CLEAN_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stuff going moment mj started listening music ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>classic war worlds timothy hines entertaining ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>film starts manager nicholas bell giving welco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>must assumed praised film greatest filmed oper...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>superbly trashy wondrously unpretentious explo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>seems like consideration gone imdb reviews fil...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>believe made film completely unnecessary first...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>guy loser get girls needs build picked stronge...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>minute documentary bu uel made early one spain...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>saw movie child broke heart story unfinished e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment\n",
       "0      stuff going moment mj started listening music ...          1\n",
       "1      classic war worlds timothy hines entertaining ...          1\n",
       "2      film starts manager nicholas bell giving welco...          0\n",
       "3      must assumed praised film greatest filmed oper...          0\n",
       "4      superbly trashy wondrously unpretentious explo...          1\n",
       "...                                                  ...        ...\n",
       "24995  seems like consideration gone imdb reviews fil...          0\n",
       "24996  believe made film completely unnecessary first...          0\n",
       "24997  guy loser get girls needs build picked stronge...          0\n",
       "24998  minute documentary bu uel made early one spain...          0\n",
       "24999  saw movie child broke heart story unfinished e...          1\n",
       "\n",
       "[25000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = list(train_data['review'])\n",
    "sentiments = list(train_data['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf-idf 값으로 벡터화\n",
    "# min-df : 설정한 값보다 특정 토큰의 df값이 적게 나오면 벡터화 과정에서 제거\n",
    "# analyzer : 분석하기 위한 기준 단위(word:단어기준, char:문자기준)\n",
    "# sublinear_tf : tf(문서 빈도수)에 대한 스무딩(smoothing) 여부 설정\n",
    "# ngram_range : 단어 묶음에 대한 범위 설정\n",
    "# max_features : 벡터의 최대 길이\n",
    "vectorizer = TfidfVectorizer(min_df = 0.0, analyzer=\"char\", \\\n",
    "                sublinear_tf=True, ngram_range=(1,3), max_features=5000)\n",
    "X = vectorizer.fit_transform(reviews)\n",
    "y = np.array(sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\TAEYONG\\anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "features = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ',\n",
       " ' a',\n",
       " ' aa',\n",
       " ' ab',\n",
       " ' ac',\n",
       " ' ad',\n",
       " ' ae',\n",
       " ' af',\n",
       " ' ag',\n",
       " ' ah',\n",
       " ' ai',\n",
       " ' ak',\n",
       " ' al',\n",
       " ' am',\n",
       " ' an',\n",
       " ' ap',\n",
       " ' ar',\n",
       " ' as',\n",
       " ' at',\n",
       " ' au',\n",
       " ' av',\n",
       " ' aw',\n",
       " ' ax',\n",
       " ' az',\n",
       " ' b',\n",
       " ' b ',\n",
       " ' ba',\n",
       " ' bb',\n",
       " ' be',\n",
       " ' bi',\n",
       " ' bl',\n",
       " ' bo',\n",
       " ' br',\n",
       " ' bu',\n",
       " ' by',\n",
       " ' c',\n",
       " ' c ',\n",
       " ' ca',\n",
       " ' ce',\n",
       " ' cg',\n",
       " ' ch',\n",
       " ' ci',\n",
       " ' cl',\n",
       " ' co',\n",
       " ' cr',\n",
       " ' cu',\n",
       " ' cy',\n",
       " ' d',\n",
       " ' da',\n",
       " ' de',\n",
       " ' di',\n",
       " ' do',\n",
       " ' dr',\n",
       " ' du',\n",
       " ' dv',\n",
       " ' dw',\n",
       " ' dy',\n",
       " ' e',\n",
       " ' e ',\n",
       " ' ea',\n",
       " ' eb',\n",
       " ' ec',\n",
       " ' ed',\n",
       " ' ee',\n",
       " ' ef',\n",
       " ' eg',\n",
       " ' ei',\n",
       " ' el',\n",
       " ' em',\n",
       " ' en',\n",
       " ' ep',\n",
       " ' eq',\n",
       " ' er',\n",
       " ' es',\n",
       " ' et',\n",
       " ' eu',\n",
       " ' ev',\n",
       " ' ex',\n",
       " ' ey',\n",
       " ' f',\n",
       " ' f ',\n",
       " ' fa',\n",
       " ' fb',\n",
       " ' fe',\n",
       " ' fi',\n",
       " ' fl',\n",
       " ' fo',\n",
       " ' fr',\n",
       " ' fu',\n",
       " ' fx',\n",
       " ' g',\n",
       " ' g ',\n",
       " ' ga',\n",
       " ' ge',\n",
       " ' gh',\n",
       " ' gi',\n",
       " ' gl',\n",
       " ' go',\n",
       " ' gr',\n",
       " ' gu',\n",
       " ' gw',\n",
       " ' gy',\n",
       " ' h',\n",
       " ' h ',\n",
       " ' ha',\n",
       " ' hb',\n",
       " ' he',\n",
       " ' hi',\n",
       " ' hm',\n",
       " ' ho',\n",
       " ' hu',\n",
       " ' hy',\n",
       " ' i',\n",
       " ' ia',\n",
       " ' ic',\n",
       " ' id',\n",
       " ' ig',\n",
       " ' ii',\n",
       " ' il',\n",
       " ' im',\n",
       " ' in',\n",
       " ' ir',\n",
       " ' is',\n",
       " ' it',\n",
       " ' iv',\n",
       " ' j',\n",
       " ' j ',\n",
       " ' ja',\n",
       " ' je',\n",
       " ' ji',\n",
       " ' jo',\n",
       " ' jr',\n",
       " ' ju',\n",
       " ' k',\n",
       " ' k ',\n",
       " ' ka',\n",
       " ' ke',\n",
       " ' kh',\n",
       " ' ki',\n",
       " ' kl',\n",
       " ' kn',\n",
       " ' ko',\n",
       " ' kr',\n",
       " ' ku',\n",
       " ' ky',\n",
       " ' l',\n",
       " ' l ',\n",
       " ' la',\n",
       " ' le',\n",
       " ' li',\n",
       " ' ll',\n",
       " ' lo',\n",
       " ' lu',\n",
       " ' ly',\n",
       " ' m',\n",
       " ' ma',\n",
       " ' mc',\n",
       " ' me',\n",
       " ' mg',\n",
       " ' mi',\n",
       " ' mm',\n",
       " ' mo',\n",
       " ' mr',\n",
       " ' ms',\n",
       " ' mu',\n",
       " ' my',\n",
       " ' n',\n",
       " ' n ',\n",
       " ' na',\n",
       " ' nd',\n",
       " ' ne',\n",
       " ' ni',\n",
       " ' no',\n",
       " ' nu',\n",
       " ' ny',\n",
       " ' o',\n",
       " ' oa',\n",
       " ' ob',\n",
       " ' oc',\n",
       " ' od',\n",
       " ' of',\n",
       " ' oh',\n",
       " ' oi',\n",
       " ' ok',\n",
       " ' ol',\n",
       " ' om',\n",
       " ' on',\n",
       " ' oo',\n",
       " ' op',\n",
       " ' or',\n",
       " ' os',\n",
       " ' ot',\n",
       " ' ou',\n",
       " ' ov',\n",
       " ' ow',\n",
       " ' oz',\n",
       " ' p',\n",
       " ' p ',\n",
       " ' pa',\n",
       " ' pe',\n",
       " ' pg',\n",
       " ' ph',\n",
       " ' pi',\n",
       " ' pl',\n",
       " ' po',\n",
       " ' pr',\n",
       " ' ps',\n",
       " ' pu',\n",
       " ' py',\n",
       " ' q',\n",
       " ' qu',\n",
       " ' r',\n",
       " ' r ',\n",
       " ' ra',\n",
       " ' rd',\n",
       " ' re',\n",
       " ' rh',\n",
       " ' ri',\n",
       " ' ro',\n",
       " ' ru',\n",
       " ' ry',\n",
       " ' s',\n",
       " ' sa',\n",
       " ' sc',\n",
       " ' se',\n",
       " ' sg',\n",
       " ' sh',\n",
       " ' si',\n",
       " ' sk',\n",
       " ' sl',\n",
       " ' sm',\n",
       " ' sn',\n",
       " ' so',\n",
       " ' sp',\n",
       " ' sq',\n",
       " ' st',\n",
       " ' su',\n",
       " ' sw',\n",
       " ' sy',\n",
       " ' t',\n",
       " ' ta',\n",
       " ' te',\n",
       " ' th',\n",
       " ' ti',\n",
       " ' to',\n",
       " ' tr',\n",
       " ' ts',\n",
       " ' tu',\n",
       " ' tv',\n",
       " ' tw',\n",
       " ' ty',\n",
       " ' u',\n",
       " ' u ',\n",
       " ' ug',\n",
       " ' uk',\n",
       " ' ul',\n",
       " ' um',\n",
       " ' un',\n",
       " ' up',\n",
       " ' ur',\n",
       " ' us',\n",
       " ' ut',\n",
       " ' v',\n",
       " ' v ',\n",
       " ' va',\n",
       " ' ve',\n",
       " ' vh',\n",
       " ' vi',\n",
       " ' vo',\n",
       " ' vs',\n",
       " ' vu',\n",
       " ' w',\n",
       " ' w ',\n",
       " ' wa',\n",
       " ' we',\n",
       " ' wh',\n",
       " ' wi',\n",
       " ' wo',\n",
       " ' wr',\n",
       " ' wu',\n",
       " ' ww',\n",
       " ' x',\n",
       " ' x ',\n",
       " ' y',\n",
       " ' ya',\n",
       " ' ye',\n",
       " ' yo',\n",
       " ' yu',\n",
       " ' z',\n",
       " ' za',\n",
       " ' ze',\n",
       " ' zi',\n",
       " ' zo',\n",
       " ' zu',\n",
       " 'a',\n",
       " 'a ',\n",
       " 'a a',\n",
       " 'a b',\n",
       " 'a c',\n",
       " 'a d',\n",
       " 'a e',\n",
       " 'a f',\n",
       " 'a g',\n",
       " 'a h',\n",
       " 'a i',\n",
       " 'a j',\n",
       " 'a k',\n",
       " 'a l',\n",
       " 'a m',\n",
       " 'a n',\n",
       " 'a o',\n",
       " 'a p',\n",
       " 'a q',\n",
       " 'a r',\n",
       " 'a s',\n",
       " 'a t',\n",
       " 'a u',\n",
       " 'a v',\n",
       " 'a w',\n",
       " 'a y',\n",
       " 'aa',\n",
       " 'aa ',\n",
       " 'aaa',\n",
       " 'aar',\n",
       " 'ab',\n",
       " 'ab ',\n",
       " 'aba',\n",
       " 'abb',\n",
       " 'abc',\n",
       " 'abe',\n",
       " 'abh',\n",
       " 'abi',\n",
       " 'abl',\n",
       " 'abo',\n",
       " 'abr',\n",
       " 'abs',\n",
       " 'abu',\n",
       " 'aby',\n",
       " 'ac',\n",
       " 'ac ',\n",
       " 'aca',\n",
       " 'acc',\n",
       " 'ace',\n",
       " 'ach',\n",
       " 'aci',\n",
       " 'ack',\n",
       " 'acl',\n",
       " 'aco',\n",
       " 'acq',\n",
       " 'acr',\n",
       " 'act',\n",
       " 'acu',\n",
       " 'acy',\n",
       " 'ad',\n",
       " 'ad ',\n",
       " 'ada',\n",
       " 'adc',\n",
       " 'add',\n",
       " 'ade',\n",
       " 'adf',\n",
       " 'adg',\n",
       " 'adh',\n",
       " 'adi',\n",
       " 'adj',\n",
       " 'adl',\n",
       " 'adm',\n",
       " 'adn',\n",
       " 'ado',\n",
       " 'adr',\n",
       " 'ads',\n",
       " 'adu',\n",
       " 'adv',\n",
       " 'adw',\n",
       " 'ady',\n",
       " 'ae',\n",
       " 'ae ',\n",
       " 'ael',\n",
       " 'aes',\n",
       " 'af',\n",
       " 'af ',\n",
       " 'afe',\n",
       " 'aff',\n",
       " 'afi',\n",
       " 'afo',\n",
       " 'afr',\n",
       " 'aft',\n",
       " 'ag',\n",
       " 'ag ',\n",
       " 'aga',\n",
       " 'age',\n",
       " 'agg',\n",
       " 'agh',\n",
       " 'agi',\n",
       " 'agl',\n",
       " 'agn',\n",
       " 'ago',\n",
       " 'agr',\n",
       " 'ags',\n",
       " 'agu',\n",
       " 'ah',\n",
       " 'ah ',\n",
       " 'aha',\n",
       " 'ahe',\n",
       " 'ahi',\n",
       " 'aho',\n",
       " 'ai',\n",
       " 'ai ',\n",
       " 'aic',\n",
       " 'aid',\n",
       " 'aig',\n",
       " 'ail',\n",
       " 'aim',\n",
       " 'ain',\n",
       " 'air',\n",
       " 'ais',\n",
       " 'ait',\n",
       " 'aiv',\n",
       " 'aj',\n",
       " 'aj ',\n",
       " 'aja',\n",
       " 'ajo',\n",
       " 'ak',\n",
       " 'ak ',\n",
       " 'aka',\n",
       " 'ake',\n",
       " 'aki',\n",
       " 'akn',\n",
       " 'ako',\n",
       " 'aks',\n",
       " 'aku',\n",
       " 'aky',\n",
       " 'al',\n",
       " 'al ',\n",
       " 'ala',\n",
       " 'alb',\n",
       " 'alc',\n",
       " 'ald',\n",
       " 'ale',\n",
       " 'alf',\n",
       " 'alg',\n",
       " 'ali',\n",
       " 'alk',\n",
       " 'all',\n",
       " 'alm',\n",
       " 'alo',\n",
       " 'alp',\n",
       " 'alr',\n",
       " 'als',\n",
       " 'alt',\n",
       " 'alu',\n",
       " 'alv',\n",
       " 'alw',\n",
       " 'aly',\n",
       " 'am',\n",
       " 'am ',\n",
       " 'ama',\n",
       " 'amb',\n",
       " 'ame',\n",
       " 'ami',\n",
       " 'aml',\n",
       " 'amm',\n",
       " 'amn',\n",
       " 'amo',\n",
       " 'amp',\n",
       " 'amr',\n",
       " 'ams',\n",
       " 'amu',\n",
       " 'amy',\n",
       " 'an',\n",
       " 'an ',\n",
       " 'ana',\n",
       " 'anc',\n",
       " 'and',\n",
       " 'ane',\n",
       " 'ang',\n",
       " 'anh',\n",
       " 'ani',\n",
       " 'ank',\n",
       " 'anl',\n",
       " 'ann',\n",
       " 'ano',\n",
       " 'ans',\n",
       " 'ant',\n",
       " 'anu',\n",
       " 'anw',\n",
       " 'anx',\n",
       " 'any',\n",
       " 'anz',\n",
       " 'ao',\n",
       " 'ao ',\n",
       " 'aor',\n",
       " 'ap',\n",
       " 'ap ',\n",
       " 'apa',\n",
       " 'ape',\n",
       " 'aph',\n",
       " 'api',\n",
       " 'apl',\n",
       " 'apo',\n",
       " 'app',\n",
       " 'apr',\n",
       " 'aps',\n",
       " 'apt',\n",
       " 'aq',\n",
       " 'aq ',\n",
       " 'aqu',\n",
       " 'ar',\n",
       " 'ar ',\n",
       " 'ara',\n",
       " 'arb',\n",
       " 'arc',\n",
       " 'ard',\n",
       " 'are',\n",
       " 'arf',\n",
       " 'arg',\n",
       " 'ari',\n",
       " 'ark',\n",
       " 'arl',\n",
       " 'arm',\n",
       " 'arn',\n",
       " 'aro',\n",
       " 'arp',\n",
       " 'arq',\n",
       " 'arr',\n",
       " 'ars',\n",
       " 'art',\n",
       " 'arv',\n",
       " 'ary',\n",
       " 'arz',\n",
       " 'as',\n",
       " 'as ',\n",
       " 'asa',\n",
       " 'asc',\n",
       " 'ase',\n",
       " 'ash',\n",
       " 'asi',\n",
       " 'ask',\n",
       " 'asl',\n",
       " 'asm',\n",
       " 'aso',\n",
       " 'asp',\n",
       " 'ass',\n",
       " 'ast',\n",
       " 'asu',\n",
       " 'asy',\n",
       " 'at',\n",
       " 'at ',\n",
       " 'ata',\n",
       " 'atc',\n",
       " 'ate',\n",
       " 'ath',\n",
       " 'ati',\n",
       " 'atl',\n",
       " 'atm',\n",
       " 'atn',\n",
       " 'ato',\n",
       " 'atr',\n",
       " 'ats',\n",
       " 'att',\n",
       " 'atu',\n",
       " 'aty',\n",
       " 'au',\n",
       " 'au ',\n",
       " 'auc',\n",
       " 'aud',\n",
       " 'aug',\n",
       " 'aul',\n",
       " 'aum',\n",
       " 'aun',\n",
       " 'aur',\n",
       " 'aus',\n",
       " 'aut',\n",
       " 'av',\n",
       " 'ava',\n",
       " 'ave',\n",
       " 'avi',\n",
       " 'avo',\n",
       " 'avy',\n",
       " 'aw',\n",
       " 'aw ',\n",
       " 'awa',\n",
       " 'awe',\n",
       " 'awf',\n",
       " 'awi',\n",
       " 'awk',\n",
       " 'awl',\n",
       " 'awn',\n",
       " 'awr',\n",
       " 'aws',\n",
       " 'awy',\n",
       " 'ax',\n",
       " 'ax ',\n",
       " 'axe',\n",
       " 'axi',\n",
       " 'ay',\n",
       " 'ay ',\n",
       " 'aya',\n",
       " 'ayb',\n",
       " 'aye',\n",
       " 'ayi',\n",
       " 'ayl',\n",
       " 'aym',\n",
       " 'ayn',\n",
       " 'ayo',\n",
       " 'ays',\n",
       " 'ayw',\n",
       " 'az',\n",
       " 'az ',\n",
       " 'aza',\n",
       " 'aze',\n",
       " 'azi',\n",
       " 'azo',\n",
       " 'azy',\n",
       " 'azz',\n",
       " 'b',\n",
       " 'b ',\n",
       " 'b a',\n",
       " 'b b',\n",
       " 'b c',\n",
       " 'b d',\n",
       " 'b e',\n",
       " 'b f',\n",
       " 'b g',\n",
       " 'b h',\n",
       " 'b i',\n",
       " 'b j',\n",
       " 'b l',\n",
       " 'b m',\n",
       " 'b n',\n",
       " 'b o',\n",
       " 'b p',\n",
       " 'b r',\n",
       " 'b s',\n",
       " 'b t',\n",
       " 'b u',\n",
       " 'b w',\n",
       " 'ba',\n",
       " 'ba ',\n",
       " 'bab',\n",
       " 'bac',\n",
       " 'bad',\n",
       " 'baf',\n",
       " 'bag',\n",
       " 'bai',\n",
       " 'bak',\n",
       " 'bal',\n",
       " 'ban',\n",
       " 'bar',\n",
       " 'bas',\n",
       " 'bat',\n",
       " 'bau',\n",
       " 'bay',\n",
       " 'bb',\n",
       " 'bba',\n",
       " 'bbc',\n",
       " 'bbe',\n",
       " 'bbi',\n",
       " 'bbl',\n",
       " 'bbo',\n",
       " 'bby',\n",
       " 'bc',\n",
       " 'bc ',\n",
       " 'bd',\n",
       " 'be',\n",
       " 'be ',\n",
       " 'bea',\n",
       " 'bec',\n",
       " 'bed',\n",
       " 'bee',\n",
       " 'bef',\n",
       " 'beg',\n",
       " 'beh',\n",
       " 'bei',\n",
       " 'bel',\n",
       " 'ben',\n",
       " 'ber',\n",
       " 'bes',\n",
       " 'bet',\n",
       " 'bew',\n",
       " 'bey',\n",
       " 'bh',\n",
       " 'bha',\n",
       " 'bi',\n",
       " 'bi ',\n",
       " 'bia',\n",
       " 'bib',\n",
       " 'bic',\n",
       " 'bid',\n",
       " 'bie',\n",
       " 'big',\n",
       " 'bik',\n",
       " 'bil',\n",
       " 'bin',\n",
       " 'bio',\n",
       " 'bir',\n",
       " 'bis',\n",
       " 'bit',\n",
       " 'biz',\n",
       " 'bj',\n",
       " 'bje',\n",
       " 'bl',\n",
       " 'bla',\n",
       " 'ble',\n",
       " 'bli',\n",
       " 'blo',\n",
       " 'blu',\n",
       " 'bly',\n",
       " 'bm',\n",
       " 'bn',\n",
       " 'bno',\n",
       " 'bo',\n",
       " 'bo ',\n",
       " 'boa',\n",
       " 'bob',\n",
       " 'bod',\n",
       " 'bog',\n",
       " 'boi',\n",
       " 'bol',\n",
       " 'bom',\n",
       " 'bon',\n",
       " 'boo',\n",
       " 'bor',\n",
       " 'bos',\n",
       " 'bot',\n",
       " 'bou',\n",
       " 'bow',\n",
       " 'box',\n",
       " 'boy',\n",
       " 'bp',\n",
       " 'bpl',\n",
       " 'br',\n",
       " 'bra',\n",
       " 'bre',\n",
       " 'bri',\n",
       " 'bro',\n",
       " 'bru',\n",
       " 'bs',\n",
       " 'bs ',\n",
       " 'bsc',\n",
       " 'bse',\n",
       " 'bsi',\n",
       " 'bso',\n",
       " 'bst',\n",
       " 'bsu',\n",
       " 'bt',\n",
       " 'bt ',\n",
       " 'bta',\n",
       " 'bte',\n",
       " 'bti',\n",
       " 'btl',\n",
       " 'bu',\n",
       " 'bu ',\n",
       " 'bub',\n",
       " 'buc',\n",
       " 'bud',\n",
       " 'buf',\n",
       " 'bug',\n",
       " 'bui',\n",
       " 'bul',\n",
       " 'bum',\n",
       " 'bun',\n",
       " 'bur',\n",
       " 'bus',\n",
       " 'but',\n",
       " 'buy',\n",
       " 'bv',\n",
       " 'bvi',\n",
       " 'by',\n",
       " 'by ',\n",
       " 'bye',\n",
       " 'byr',\n",
       " 'bys',\n",
       " 'c',\n",
       " 'c ',\n",
       " 'c a',\n",
       " 'c b',\n",
       " 'c c',\n",
       " 'c d',\n",
       " 'c e',\n",
       " 'c f',\n",
       " 'c g',\n",
       " 'c h',\n",
       " 'c i',\n",
       " 'c j',\n",
       " 'c k',\n",
       " 'c l',\n",
       " 'c m',\n",
       " 'c n',\n",
       " 'c o',\n",
       " 'c p',\n",
       " 'c r',\n",
       " 'c s',\n",
       " 'c t',\n",
       " 'c u',\n",
       " 'c v',\n",
       " 'c w',\n",
       " 'c y',\n",
       " 'ca',\n",
       " 'ca ',\n",
       " 'cab',\n",
       " 'cad',\n",
       " 'cag',\n",
       " 'cai',\n",
       " 'cak',\n",
       " 'cal',\n",
       " 'cam',\n",
       " 'can',\n",
       " 'cap',\n",
       " 'car',\n",
       " 'cas',\n",
       " 'cat',\n",
       " 'cau',\n",
       " 'cav',\n",
       " 'cb',\n",
       " 'cc',\n",
       " 'cca',\n",
       " 'cce',\n",
       " 'cci',\n",
       " 'ccl',\n",
       " 'cco',\n",
       " 'ccu',\n",
       " 'cd',\n",
       " 'cdo',\n",
       " 'ce',\n",
       " 'ce ',\n",
       " 'cea',\n",
       " 'cec',\n",
       " 'ced',\n",
       " 'cee',\n",
       " 'cef',\n",
       " 'cei',\n",
       " 'cel',\n",
       " 'cem',\n",
       " 'cen',\n",
       " 'cep',\n",
       " 'cer',\n",
       " 'ces',\n",
       " 'cet',\n",
       " 'cey',\n",
       " 'cg',\n",
       " 'cgi',\n",
       " 'ch',\n",
       " 'ch ',\n",
       " 'cha',\n",
       " 'chc',\n",
       " 'che',\n",
       " 'chi',\n",
       " 'chl',\n",
       " 'chm',\n",
       " 'chn',\n",
       " 'cho',\n",
       " 'chr',\n",
       " 'cht',\n",
       " 'chu',\n",
       " 'chw',\n",
       " 'chy',\n",
       " 'ci',\n",
       " 'ci ',\n",
       " 'cia',\n",
       " 'cid',\n",
       " 'cie',\n",
       " 'cif',\n",
       " 'cig',\n",
       " 'cil',\n",
       " 'cin',\n",
       " 'cio',\n",
       " 'cip',\n",
       " 'cir',\n",
       " 'cis',\n",
       " 'cit',\n",
       " 'civ',\n",
       " 'ciz',\n",
       " 'ck',\n",
       " 'ck ',\n",
       " 'cka',\n",
       " 'ckb',\n",
       " 'ckd',\n",
       " 'cke',\n",
       " 'ckg',\n",
       " 'ckh',\n",
       " 'cki',\n",
       " 'ckl',\n",
       " 'ckm',\n",
       " 'ckn',\n",
       " 'cko',\n",
       " 'cks',\n",
       " 'ckt',\n",
       " 'ckw',\n",
       " 'cky',\n",
       " 'cl',\n",
       " 'cla',\n",
       " 'cle',\n",
       " 'cli',\n",
       " 'clo',\n",
       " 'clu',\n",
       " 'cm',\n",
       " 'cn',\n",
       " 'co',\n",
       " 'co ',\n",
       " 'coa',\n",
       " 'cob',\n",
       " 'coc',\n",
       " 'cod',\n",
       " 'coe',\n",
       " 'cof',\n",
       " 'cog',\n",
       " 'coh',\n",
       " 'coi',\n",
       " 'col',\n",
       " 'com',\n",
       " 'con',\n",
       " 'coo',\n",
       " 'cop',\n",
       " 'cor',\n",
       " 'cos',\n",
       " 'cot',\n",
       " 'cou',\n",
       " 'cov',\n",
       " 'cow',\n",
       " 'cox',\n",
       " 'coy',\n",
       " 'cq',\n",
       " 'cqu',\n",
       " 'cr',\n",
       " 'cra',\n",
       " 'cre',\n",
       " 'cri',\n",
       " 'cro',\n",
       " 'cru',\n",
       " 'cry',\n",
       " 'cs',\n",
       " 'cs ',\n",
       " 'ct',\n",
       " 'ct ',\n",
       " 'cta',\n",
       " 'cte',\n",
       " 'cti',\n",
       " 'ctl',\n",
       " 'cto',\n",
       " 'ctr',\n",
       " 'cts',\n",
       " 'ctu',\n",
       " 'cu',\n",
       " 'cub',\n",
       " 'cue',\n",
       " 'cul',\n",
       " 'cum',\n",
       " 'cun',\n",
       " 'cup',\n",
       " 'cur',\n",
       " 'cus',\n",
       " 'cut',\n",
       " 'cy',\n",
       " 'cy ',\n",
       " 'cyb',\n",
       " 'cyc',\n",
       " 'cyn',\n",
       " 'cz',\n",
       " 'd',\n",
       " 'd ',\n",
       " 'd a',\n",
       " 'd b',\n",
       " 'd c',\n",
       " 'd d',\n",
       " 'd e',\n",
       " 'd f',\n",
       " 'd g',\n",
       " 'd h',\n",
       " 'd i',\n",
       " 'd j',\n",
       " 'd k',\n",
       " 'd l',\n",
       " 'd m',\n",
       " 'd n',\n",
       " 'd o',\n",
       " 'd p',\n",
       " 'd q',\n",
       " 'd r',\n",
       " 'd s',\n",
       " 'd t',\n",
       " 'd u',\n",
       " 'd v',\n",
       " 'd w',\n",
       " 'd y',\n",
       " 'd z',\n",
       " 'da',\n",
       " 'da ',\n",
       " 'dab',\n",
       " 'dac',\n",
       " 'dad',\n",
       " 'dag',\n",
       " 'dah',\n",
       " 'dai',\n",
       " 'dal',\n",
       " 'dam',\n",
       " 'dan',\n",
       " 'dap',\n",
       " 'dar',\n",
       " 'das',\n",
       " 'dat',\n",
       " ...]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_eval, y_train, y_eval = train_test_split(X,y,test_size=TEST_SPLIT, \\\n",
    "                                    random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class_weight='balanced' : 각 레이블에 대해 균형있게 학습\n",
    "lgs = LogisticRegression(class_weight='balanced')\n",
    "lgs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = lgs.predict(X_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.859800\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %f\" % lgs.score(X_eval, y_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_CLEAN_DATA = 'test_clean.csv'\n",
    "\n",
    "test_data = pd.read_csv(DATA_IN_PATH + TEST_CLEAN_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataVecs = vectorizer.transform(test_data['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 ... 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "test_predicted = lgs.predict(testDataVecs)\n",
    "print(test_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(DATA_OUT_PATH):\n",
    "    os.makedirs(DATA_OUT_PATH)\n",
    "\n",
    "answer_dataset = pd.DataFrame({'id':test_data['id'],'sentiment': \\\n",
    "                test_predicted})\n",
    "\n",
    "answer_dataset.to_csv(DATA_OUT_PATH + 'lgs_tfidf_answer.csv', \\\n",
    "                index=False, quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"12311_10\"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"8348_2\"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"5828_4\"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"7186_2\"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"12128_7\"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>\"2155_10\"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>\"59_10\"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>\"2531_1\"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>\"7772_8\"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>\"11465_10\"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  sentiment\n",
       "0      \"12311_10\"          1\n",
       "1        \"8348_2\"          0\n",
       "2        \"5828_4\"          1\n",
       "3        \"7186_2\"          0\n",
       "4       \"12128_7\"          1\n",
       "...           ...        ...\n",
       "24995   \"2155_10\"          1\n",
       "24996     \"59_10\"          1\n",
       "24997    \"2531_1\"          0\n",
       "24998    \"7772_8\"          1\n",
       "24999  \"11465_10\"          0\n",
       "\n",
       "[25000 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study",
   "language": "python",
   "name": "study"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e99cd6124d1454c43974c193ef05ef59cc7820eb47b987c9c9e53e57b79f92b9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
