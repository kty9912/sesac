자연어 처리 과정
= 텍스트 데이터 수집
= 한국어 패키지 적용
    (Pycospacing:띄어쓰기, Py-Hanspell:맞춤법 검사)
= 문장 토큰화
= 단어 토큰화
= 불용어 처리
=>이전 과정의 내용 : 본문 데이터로 지칭
------------------------
= 단어별 빈도수 카운트(word_counts)
= 빈도수별 순위 매기기(word_index)
= word_to_index에 OOV 추가
--------------
= 인코딩
 - label 인코딩(본문 데이터)
 - one-hot 인코딩
 - 카운트 기반의 단어 표현
    1) BOW(한문장 빈도수)
    2) DTM(여러문장 빈도수)
    3) TF-IDF
= 패딩(데이터 길이 맞추기)
= LSA(주제분석) : 단어간의, 문장간의 빈도수 흐름 파악
********************
감성분석 프로젝트
1. 로지스틱 회귀분석
   - 가중치를 통해서 Y값을 기준으로 한 긍/부정 단어 파악
   - 희소행렬 압축 변환
      : x로 할당된 DTM의 경우는 CSR방식,
      : model.fit을 할경우는 x.A로 압축을 풀어서 input으로 넣어야함
        (문제점 : 대용량 Text인 경우는 훈련시 문제가 생길수 있음)
      : model.fit은 coo 압축 데이터를 input으로 받을 수 있음
        (그래서 CSR방식의 DTM을 COO방식으로 변환)
   - Early Stopping
2. 언어모형 + 전이 학습
    - 신경망 적용
3. FastText
    - 준단어 토큰화를 이용한 단어임베딩 기법